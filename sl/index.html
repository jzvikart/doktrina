<html>
<head>
    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <!-- Google Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-60136920-1', 'auto');
    ga('send', 'pageview');
    </script>
    <!-- End Google Analytics -->
    <link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">
    <style type="text/css">
        body {
        	background: #e0e0e0;
        	font-family: 'Roboto', sans-serif;
        	font-size: 20;
        	margin: 0px;
        }
        #topbar {
        	padding: 10px 10px 10px 10px;
        	margin: 0 0 0 0;
        	background-color: #606060;
        }
        #topbar>h1 {
        	margin: 0;
        	color: #ffffff;
        }
        #main {
        	margin: 10 10 10 10;
        }
        #main>h2 {
        	color: #0c1e66;
        }
    </style>
    <title>Introduction to Doktrina</title>
</head>
<body>
<div id="topbar">
<h1>Doktrina</h1>
</div>
<div id="main">
<h2>Uvod</h2>

<p>V resnici "doktrina" ni nič zares novega. Takorekoč vsi opisani koncepti že obstajajo in se na široko uporabljajo, vendar v zelo različnih kontekstih, nepovezano in na različne načine. V samem bistvu gre za odpravo ovir in vzpostavitev določenih abstrakcij, ki nam bi omogočile delo v bolj homogenem in ortogonalnem virtualnem svetu. S tem želimo vzpostaviti trajnostno naravnan ekosistem, v katerem so člani skupnosti motivirani, da probleme rešujejo skupaj, enkrat in za vselej, namesto da vsakič znova izumljajo vsak svoje kolo. Povedano drugače, glavni cilj je enostavnost, čista arhitektura, preglednost, ter sposobnost opisa programa na človeku prijazen način.</p>

<h2>Simboli</h2>

<p>Sporazumevanje med človekom in strojem v doktrini poteka preko simbolov. Za človeka simbol predstavlja nek natančno določen pojem - praviloma ga določi tisti, ki simbol ustvari - in ima vlogo stičišča med svetovi. Z vidika stroja simbol služi zgolj za ugotavljanje istovetnosti (identitete). Lokacija simbolov je abstrahirana, tako da se razvijalcu s tem ni treba ukvarjati, razen da na nek način nedvoumno opiše, kateri simbol ima v mislih (npr. ga izbere iz kataloga na spletni strani, poskenira QR kodo ipd.). Podobno kot npr. pri URL-jih je v ozadju nek mehanizem, ki zna iz oznake locirati definicijo in vsebino simbola preko enega ali večih protokolov za razreševanje (dereferencing). Ker so simboli enolični, nikoli ne pride do trčenja imen, verzij ipd. Tehnično gledano je simbol posplošitev naslova (GUID, pointer, URI, IP...) in ima to lastnost, da ga mu je mogoče dodati predpono in ga bijektivno preslikati v neko zaporedje bitov.</p>

<p>Simboli (oz. natančneje stvari, ki jih predstavljajo) se med seboj povezujejo in s tem tvorijo grafe. Struktura povezav določa semantiko (npr. "vsak človek ima ime" pomeni, da ima vsak simbol, ki predstavlja človeka, povezavo do drugega simbola, ki predstavlja njegovo ime).

<p>(Razlog, ki tiči v ozadju tega pristopa, je večplasten. Prvič, simbolično razmišljanje je za človeka naravno, neodvisno od jezika ali kulture in omogoča abstraktno sklepanje. Za stroj je simbol zelo prikladen, saj omogoča učinkovito implementacijo. Simbol ločuje pomen od vsebine. Ker se ljudje zelo težko dogovorimo glede enotnih standardov za karkoli, je nesmiselno pričakovati, da bo kadarkoli lahko obstajal en sam skupen, vseobsegajoč standard. Veliko lažje se je dogovoriti glede metastandarda - to je standarda o tem, kako se sprejemajo in zapisujejo standardi - ter s tem omogočiti hkraten soobstoj različnih standardov, med katerimi vlada "naravna selekcija" in natančno definirani medsebojni odnosi. S primernim metastandardom lahko pokrijemo tudi druge (bodoče) metastandarde, kar vsaj v teoriji pomeni, da lahko postavimo neko rekurzivno in dolgoročno izhodišče za nadaljnje delo.)

<p>Ker so simboli povsem abstraktni, je možno, da ima isti simbol različne predstavitve. Recimo pojem, ki je v angleščini imenovan Person je lahko v slovenščini predstavljen kot Oseba, v nekem tretjem okolju pa z ikono človečka. Ker je v ozadju isti simbol, nikoli ni zmešnjave, semantika tega simbola pa je vedno enaka ne glede na to, ali z njim manipuliramo v grafičnem okolju (z ikono), v tekstovnem okolju (z imenom) ali kako drugače. Denimo, če zvlečemo ikono človečka na ikono avtomobila, je v ozadju tega klic funkcije "oseba se pelje z avtom", in to je popolnoma enako kot če bi to funkcijo poklicali v kodi ali v ukazni vrstici. Princip simbolov je tako univerzalen, da ga je možno neposredno aplicirati tudi na druge vrste vmesnikov (prepoznavanje glasu/zvok, geste/kinestetika, možganski valovi...). Če ga ne potrebujemo, simbolu ni treba dati imena oz. "človeške" predstavitve (primerjava z anonimnimi razredi), ker je njegova identiteta določena že sama po sebi. Po drugi strani lahko predstavitev dodamo kadarkoli, vključno med tem, ko se program izvaja. Ker je ime/ikona zapisana samo na enem mestu, tudi ni problema s preimenovanjem oz. refactoringom.

<p>Na podoben način so "normalizirani" tudi vsi drugi deli sistema: kadarkoli gre za isto stvar, je predstavljen z enakim simbolom in eno samo kopijo podatka, ki jo uporabljajo vsi deli, ki se nanjo sklicujejo. Hkrati to pomeni, da je npr. angleška različica nekega programa lahko dosledno in na vseh nivojih angleška, slovenska pa res slovenska (od uporabniškega vmesnika do imen tabel v bazi in spremenljivk v kodi).</p>

<p>Namen normalizacije je doseči, da se različni vidiki nekega sistema ne mešajo med sabo (ortogonalnost). Torej če gledamo recimo poslovno logiko za sklenitev zavarovanja, zapis teh navodil ni onesnažen z nobenim drugim vidikom kot npr. klici webservice-ov, avtorizacijo uporabnika, shranjevanjem podatkov v bazo, branjem datotek ali podobno. Zapis sklenitve zavarovanja uporablja lasten domenski podmodel (= nabor simbolov) in izraža izključno pravila, kaj sklenitev zavarovanja pomeni v zavarovalniškem jeziku. Na enak način je nekje drugje vidik avtorizacije uporabnika opisan v enakem formalnem modelu, a v drugem domenskem podmodelu in ne vsebuje nobenih simbolov o verziji brskalnika, uporabljenih protokolov, in tako dalje. V primeru zavarovalnice tako lahko dosežemo (a) da je vsa logika za sklenitev zavarovanja zbrana na enem mestu in (b) izolirana od vse druge logike, ki s sklepanjem zavarovanja nima ničesar skupnega. To pomeni, da ko smo to logiko enkrat vnesli, ni več nobene potrebe po spreminjanju, razen če se spremenijo sama poslovna pravila. V primerjavi z npr. Javo je to sicer teoretično možno, a je skrajno nepraktično (eksplozija števila razredov), za nameček pa nam različna orodja in knjižnice vsiljujejo mešanje konceptov.</p>

<p>Sam sistem je v osnovi netipiziran, kar pomeni, da so vozlišča v grafu lahko poljubno povezana. S tem dosežemo univerzalnost. Tipiziranje je dodatni "feature" v obliki omejitev, ki jih lahko vklapljamo postopoma in tako gradimo sistem skladno z nivojem zakonitosti, ki v nekem trenutku veljajo za določene podatke. S tem dobimo možnost specificiranja sistema po korakih; npr. na začetku projekta, ko je informacij malo, začnemo z nestrukturiranimi podatki (zapisniki s sestankov kot prosto besedilo, posnetki telefonskih pogovorov, prazni placeholderji ipd.), nato pa jih postopno bogatimo, strukturiramo in vklapljamo "constraint enforcement". Na primer, ko smo podatke o osebak prečistili tako, da ima vsak človek podatek o imenu, vklopimo constraint "ima(oseba, ime)". Tipizirani in netipizirani svet obstajata vzporedno, in prehod med njima je zvezen. To pomeni, da se nismo več prisiljeni odločati bodisi za eno ali drugo, ampak lahko mešamo in izbiramo glede na to, kaj je v posameznem primeru bolje. Ko vklopimo nek constraint (npr. "številka zavarovanja mora biti enolična", "vsaka oseba ima ime" ipd.), bo pač sistem preverjal in preprečeval vse nadaljnje spremembe na grafu, ki bi povzročile kršitev tega pravila. V tem smislu "tip podatka" ni nič drugega kot podatek o podatku (metapodatek), in z njim lahko delamo kot z vsakim drugim podatkom, brez da bi bili omejeni na to, ali se stvar dogaja v času načrtovanja,  razvoja ali med produkcijskim delovanjem.</p>

<p>Izvajalno okolje je sestavljeno iz enega ali večih vozlišč, ki so med seboj povezana s kanali. Vozlišče je tipično nek proces (ali skupina sodelujočih procesov), ki tečejo na operacijskem sistemu (analogija "virtual machine" v Javi oz. "instanci" v Oracle-u). Vozlišče predstavlja abstrakten CPU in deluje po principu mikrojedra. Ob zagonu mikrojedro ponuja (izpostavlja) peščico vgrajenih simbolov, med drugim za kreiranje novega podatka, nastavljanje povezave med dvema podatkoma, razreševanje simbola, klic funkcije in prenos sporočila po kanalu. Kanal je lahko katerakoli tehnologija, ki je sposobna prenašati informacije. Z vidika komunikacije je transparentno, ali gre pri tem za poštnega goloba ali TCP povezavo. Dvosmerni kanal je sestavljen iz dveh enosmernih. En OS lahko poganja več instanc. Ena instanca ne more biti na več OS-ih (predpostavljamo skupen naslovni prostor). Komunikacija med instancami je mogoča izključno preko kanalov, ki prenašajo serializiran zapis (zaporedje byte-ov z neko predpisano strukturo).</p>

<p>Ukazi oz. "strojna koda" je prav tako sestavljena iz množice simbolov. Koda je poseben tip podatka, ki ima dodatno lastnost, da jo stroj razume. V osnovi je koda drevo oz. mreža (lattice) simbolov s podobno zgradbo kot AST. Ker je koda zgolj podatek, to pomeni, da lahko kodo gradimo in manipuliramo med samim izvajanjem programa na enak način kot katerikoli drugi tip podatka. S tem izginejo potrebe po templateih, copy-pasteanju, generičnih funkcijah, avtomatsko generirani kodi ipd. Nabor simbolov, ki jih mikrojedro razume, je minimalen, kar pomeni, da je vsa stvar portabilna z minimalnim naporom. Pojem template-a je enakovreden funkciji z N parametri (parameter = "prostorček" v templateu, kjer se izpiše podatek, rendering = klic funkcije). Templateing engine je en sam, univerzalen, in ga lahko uporabimo za genenriranje kode, PDF reportov, CSS preprocesor, ali kaj drugega. (Primerjava: LISP macro)</p>

<p>Sistem, ki ga gradimo s simboli, ima lastnost samopodobnih DSL-jev. Torej v principu ne potrebujemo več enega jezika za HTML, enega za odjemalca, enega za back-end in enega za build projekta. Vse teče v enotnem okolju, je del enotne sintakse, le da je pač nabor simbolov različen glede na posamezni namen. Npr. če potrebujemo HTML, preprosto "include-amo" množico simbolov, ki predstavljajo DOM elemente. Da iz tega dobimo spletno stran, "include-amo" še simbol za spletni strežnik in mu podamo DOM drevo kot parameter. (Seveda nič ne preprečuje, da ne bi nad tem konceptom zgradili še vmesnega koraka in in dobili "old-school" sistem, kjer je HTML zapisan v datoteki, do katere HTTP strežnik dostopa kot smo navajeni.)</p>

<p>Sam razvoj ni več omejen na pisanje datotek z besedilom. Gre za vnos in urejanje nekega dela podatkov, ki so v sistemu, na nek specifičen način oz. skozi nek primeren uporabniški vmesnik. Z vidika doktrine je to še vedno samo dostop do podatkov skozi klice nekih funkcij. Torej, če želimo, lahko kadarkoli iz teh podatkov zgeneriramo klasično kodo (množico datotek), ki predstavljajo določeno podmnožico simbolov, le da v drugem pogledu. In seveda si lahko vsak razvijalec nastavi svoj slog oklepajev, tabulatorjev, imen ipd., saj so z vsebinskega vidika dejansko pomebne samo preslikave v simbole (parsing + linking). Dodatna prednost je, da si lahko vsak razvijalec sam prilagodi "zoom factor" glede na stopnjo specifičnosti in del domenskega modela, v katerem dela. Torej npr. programerju ni treba več poznati celotne kode ali tega, kako se namešča na strežnik in tega, kje so shranjeni podatki ipd., ampak se osredotoči na življenje in delo na svojem "otočku". S tem se drastično zmanjša čas uvajanja, poveča učinkovitost in kontrola nad kvaliteto. To je torej na las podobno razvoju mikrostoritev, le da je v tem primeru vsaka funkcija že sama po sebi tudi mikrostoritev oz. za to ni potrebnega nobenega dodatnega dela.</p>

<p>Objektna in funkcijska paradigma sta združeni na tak način, da med objektom in funkcijo praktično ni razlik. "Čista funkcija" je zgolj objekt brez stanja, po drugi strani pa je vsak objekt mogoče "poklicati" in se lahko obnaša kot funkcija. S tem dobimo zvezen prehod med obema svetovoma. Funkcije imajo metapodatke, ki jih sistem razume; torej npr. ve, da plus(1, 1) ni treba računati vsakič znova, random(10) pa mora.</p>

<p>Objekt (ali funkcija) je lahko specificiran po plasteh (ekvivalentno: prototyping, currying). To omogoča deljenje skupnih informacij po nivojih, hkrati pa nam daje možnost specifikacije sistema po logičnih korakih. Množico dejstev (facts) lahko razdelimo po "prosojnicah", ki jih nato enostavno položimo eno čez drugo in se njihov pomen sešteje. Gre za podoben pristop kot pri datotečnem sistemu overlay, le da je tu na nivoju samih objektov. To ima zelo zaželjeno lastnost deduplikacije oziroma zelo poceni "delovnih kopij", kar pomeni da je vsak klic funkcije lahko npr. izveden v svojem zasebnem virtualnem okolju (podobno kot docker ali chroot). To pomeni, da za nivo granularnosti virtualizacije lahkovzamemo posamezne objekte - kar je dolgoročno gledano edina resnična virtualizacija. Progresivna specifikacija sistema je uporabna tudi pri skupnem delu na projektu: npr. designer specificira "plast" grafične postavitve elementov na strani, naročnik specificira "plast" poslovnih zahtev, deployer specificira "plast" parametrov za izvajanje v nekem specifičnem okolju ipd. Koncepti med njimi se po definiciji ujemajo, saj se sklicujejo na iste simbole. Ko vse plasti združimo, je pač sistem "100% definiran" in ga lahko poženemo (oz. v drugem smislu: funkcija ima podane vse parametre in jo lahko pokličemo). Vsebinsko gledano vključevanje podatkov iz večih plasti pokrije tudi koncept multiple inheritance.</p>

<p>Same funkcije niso grupirane po objektih, kot smo navajeni iz OO sveta, ampak živijo neodvisno življenje. Enako kot vsi drugi podatki tudi same zapadejo v garbage collection, ko jih nič več ne naslavlja. Za človeško komoditeto jih lahko grupiramo na poljubne načine, vključno s tem, da se ista funkcija pojavi v večih "katalogih" ali pa v nobenem. S tem ni več potrebe, da bi uvajali umetne soodvisnosti, ki so v OO modelu posledica vsiljenih subjektivnih odločitev in specifične od človeka do človeka (in posledično vir entropije). Preprosto: če funkcija potrebuje nek podatek, ga sprejme preko parametra. Eden od parametrov je lahko tudi "this" (referenca na trenutni objekt). Prav tako ni več samo dvonivojske hierarhije razred : objekt (1:N), ampak je hierarhija 1:N lahko gnezdena poljubno globoko (vesolje : sistem : koncept : skupina : razred : objekt : izjema). Vesolje pa je vedno samo eno (singleton).</p>

<p>Funkcija je lahko podana v različnih oblikah: kot zaporedje ukazov (imperativno), kot množica pravil (deklarativno), kot tabela, kot nastavek za komunikacijo preko kanala, kot nastavek za klic strojne naprave, ali kako drugače. Sistemu je vseeno. Ker je specifikacija ("pogodba") vedno ločena od implementacije, je vedno pomembna samo pogodba, ki je del simbola. Npr. če imamo pogodbo za http server, je zadaj lahko Apache, Nginx ali Tomcat. Dodatna prednost tega je, da je v primeru napake vedno jasno, čigava je odgovornost. Seveda pa je glavno breme s tem prestavljeno na pisanje pogodb, ki morajo biti zelo jasne, natančne in na nek način zbrane skupaj po namenu uporabe. A ker so simboli enolični, tehnično gledano lahko zgradimo "planetarno wikipedio" teh simbolov, kjer na nek način programer pač najde tisto, kar potrebuje, sama stran pa je že hkrati del dokumentacije in vsebuje tudi simbol (enolično identiteto) stvari, ki jo opisuje.</p>

<p>Pojma razvoja (development) in uporabe (production) sta izenačena. Vsaka interakcija s sistemom je preprosto njegova "uporaba". To pomeni, da je npr. razvijalec poslovne rešitve izenačen s končnim uporabnikom, razlika je samo v naboru simbolov (in okolju), v katerem delata. Delata nad istimi podatki, le v različnih pogledih. Vsebinsko gledano je to nekako podobno kot npr. MS Access, kjer je v isti "datoteki" vse, kar se tiče sistema. S tem odpade še ena dilema: razvojnemu podjetju, ki razvija nek produkt za več različnih naročnikov, ni treba več tlačiti unije pojmov vseh naročnikov pod isto streho oz. v isti projekt, ampak dela na generičnem produktu. Kadar pa rešuje problem za stranko, se enostavno poveže na njihov sistem in svoje delo opravi na njihovih podatkih in znotraj njihovega domeskega modela.</p>

<p>Ključno je to, da danes ne moremo več delati sistemov tako kot včasih, ko je programer lahko predvidel vse tipe podatkov in jih "zapekel" v sistem, kot denimo v primeru tabel v bazi. Večina resnih sistemov danes potrebuje aplikativen sistem tipov, ki se dinamično spreminja med vsakdanjim delom navadnih uporabnikov (npr. zavarovalnica definira nov zavarovalniški produkt). V ekvivalentu današnjega sveta bi to pomenilo, da končni uporabnik kreira tabele v bazi, kar pomeni nov cikel razvoja, novo testiranje, migracijo... v primeru doktrine pa to pomeni, da je sistem tipov en sam, enonivojski in homogen, in da je vseeno, ali ga spreminja programer ali končni uporabnik. Edina razlika je pač v nivoju pravic, ki jih ima oseba, ki dela s sistemom, ter v uporabniškem vmesniku. Ko je nek pojem (zavarovalniški produkt) definiran, se avtomatsko pojavi na vseh nivojih in v vseh pogledih za vse, ki delajo s sistemom - v menijih, v kodi, v bazi, v toolbarih ipd.</p>

<p>Podobno vlogo kot ima "physics engine" v igrah, predstavlja možnost deklarativnega programiranja. Z vidika uporabnika imamo nek svet (podatke), ki jih mikrojedro oživlja (preračunava) na osnovi pravil, ki se nanašajo na specifične pogoje. Preprosto povedano to pomeni, da programerju ni treba več pisati navodil v smislu "če nekdo poseka drevo, potem se to prevrne in pade na tla" in "če drevo med padanjem zadane v hišo, jo podre", ampak znanje poda v obliki dejstev (drevo ima maso, velikost, težišče; avto ima smer in hitrost, hiša ima nosilnost itd.). Namesto da bi imeli v glavi vse možne kombinacije scenarijev, se nam s tem odpre celoten navidezni svet: v drevo se lahko zaletimo z avtom, ga požagamo ali vanj vržemo skalo; na hišo lahko pade drevo, avto ali druga hiša, in tako dalje. Torej engine dinamično "računa", kaj se zgodi tako, da sledi pravilom, ki jih ima o svetu, glede na trenutno stanje sveta. Specifikacije, ki so opisane s pravili, so že po naravi na kožo pisane paralelnemu procesiranju, in bodo tem bolj primerne za nove generacije procesorjev z velikim številom jeder. Dodatna prednost je to, da se s takim načinom naravno razdelijo vloge posameznih akterjev, ki podajajo svoje znanje o sistemu: npr. strokovnjak za sklepanje zavarovanj opiše samo pravila, ki se tičejo zavarovanj, strokovnjak za drevesa opiše samo pravila, ki se tičejo dreves ipd. Posledica je tudi to, da sprememba nekega pravila ne povzroči verižne reakcije, zaradi katere je npr. v današnjih sistemih tolikokrat  treba popravljati kodo po vseh plasteh sistema in pri tem skrbeti, da nismo česa pozabili. Ker sistem pravila sproti preračunava, je učinek spremembe pravil takojšen in sistematičen: Npr. ko damo hiši pojem mase, avtomatsko vse hiše, ki so prej lebdele v zraku, popadajo na tla. Če med padanjem zadanejo v drugo hišo, se bo avtomatsko sprožilo tudi pravilo o podiranju hiš. Sistem, ki je opisan s pravili, se ne obnaša več samo kot program, ampak kot simulacija in je zato neskončno fleksibilen: dodajanje zahtev ima (približno) konstantno zahtevnost implementacije (seveda na račun porabe strojnih virov, kar pa je zanemarljiva cena v primerjavi s porabo človeškega časa).</p>

<p>Ideja procesiranja na osnovi pravil je v tem, da programer lahko izrazi zahteve v obliki "kaj" in ne več "kako" tako kot dosedaj. V ozadju je podan nabor pravil (dejstev oz. abstraktnih fizikalnih zakonov), s katerimi vhod preslikamo v izhod. Začenši z vhodom (drevesom oz. mrežo, ki predstavlja simbolični zapis naloge) poiščemo pravilo, ki je najbolj specifično, torej tisto, ki velja za korenski element. Če ga ni, nadaljujemo z iskanjem na podelementih (in tako dalje). Aplikacija vsakega pravila pomeni transformacijo enega od delov drevesa. To pomeni, da simbolično zapisan klic ene funkcije lahko v resnici sproži večje število dejanskih  klicev / transformacij, ki "napadejo" vhodni podatek (parametre) in ga začnejo transformirati, s tem pa sinergistično prispevajo k izračunu rezultata. Na primer, če si predstavljamo nalogo "razveljavi zavarovanja z osebami, ki imajo zlomljeno nogo", bo najprej eno od pravil na osnovi pattern matchinga v drevesu prepoznalo izraz "vse osebe" in na njegovo mesto v drevesu pripelo nek iterator. Drugo pravilo se bo ujelo na iterator oseb in med njimi "polovilo" tiste z zlomljeno nogo. Tretie pravilo se bo ujelo na definicijo "vsa zavarovanja" in ga zamenjalo z iteratorjem. Na koncu bo pa neko pravilo opazilo, da ima opravka z izrazom oblike "naredi X nad Y", in nad iteratorjem Y pognalo for-each zanko s klicem X za vsak element. Seveda se lahko tega konkretnega problema lotimo tudi drugače; primer je zgolj za ilustracijo. Bistveno je to, da zna engine sam "izpeljati" rezultat iz vhodnega opisa problema s pomočjo pravil, ki smo mu jih podali. Pravila so neodvisna drugo od drugega in transformacija poteka, dokler obstaja vsaj eno pravilo, ki ga je mogoče aplicirati.</p>

<p>Ločitev deklaracije od implementacije ima še druge uporabne posledice. Takoj, ko je dogovorjena "pogodba" glede nečesa, se lahko razvojni proces paralelizira. V današnjem jeziku to pomeni, da se lahko začne pisati koda, ki bo neko funkcionalnost uporabljala takoj, ko se dogovorimo o imenu oz. še preden ta funkcionalnost sploh obstaja. Enako tudi testi. To je podobno kot če bi v Javi vsako metodo dali v svoj class, pred razred pa bi postavili še interface. Tisti, ki zadevo implementira, ima možnost najprej narediti hitro implementacijo z uporabo višjenivojskih konstruktov; kasneje pa, če se pokaže potreba, lahko isto implementacijo zamenja z bolj specifično in učinkovito (npr. sprogramira pravilo za transformacijo korenskega elementa drevesa v assemblerju).</p>

<p>In ne samo to, sistemu je popolnoma vseeno, če neko funkcijo kliče človek ali stroj. To odpre vrsto zanimivih možnosti, ker se ustvarijo pogoji za nastanek API-based ekonomije. V taki ekonomiji vsak klic funkcije predstavlja neko izmenjavo vrednosti. Na primer, če imamo sistem, ki zahteva vnos nekih podatkov, lahko to funkcijo najprej kliče človek (zavarovalniški agent prepiše podatke z lista papirja v nek GUI), nato jo outsourceamo (najamemo 1000 Indijcev, ki s tem dobijo delo), ali pa slednjič razvijemo nek algoritem, ki to počne avtomatsko (OCR) in ga ponudimo vsem zainteresiranim na svetu, ki potrebujejo rešitev takega problema. Klic funkcije je lahko beležen v billing sistemu, kar pomeni da se s tem ustvarijo motivatorji za specializacijo po namembnostih - npr. neka firma se specializira na vnos Shakespearovih besedil, druga firma za postavljanje ograj ob cestah, tretja pa spet za "broking" povpraševanja in ponudbe. Skupno pa imajo to, da vse komunicirajo preko API-jev oz. izmenjave dogovorjenih simbolov.</p>

<p>Hipotetični primer: recimo, da želimo zgraditi hišo. Najprej zberemo skupaj API-je (simbole) gradbenih firm, upravnih enot, elektro podjetij, bank, itd. in jih sestavimo skupaj v en parametriziran klic funkcije, ki opravi nalogo po vseh pravilih od odobritve kredita, pridobitve gradbenega dovoljenja, do naročila za vgradnjo oken. Priprava take funkcije ima denimo kompleksnost gradnje 1000 hiš. Klic take funkcije, ko je enkrat narejena, je takorekoč zastonj. A če bo od takrat naprej kdorkoli želel enako hišo kot mi, mu tega ni treba početi znova od začetka, ampak preprosto pokliče funkcijo, ki smo jo mi dodali v ekosistem, le da s svojimi parametri (številko bančnega računa, barvo ploščic v kopalnici itd.). Seveda, bolj ko smo funkcijo gradnje hiše uspeli abstrahirati (parametrizirati), bolj je uporabna in prej se investicija vloženega časa/denarja povrne. Vsaj v teoriji tako kot civilizacija pridobimo možnost eksponentne rasti: ko je problem gradnje hiše enkrat rešen, je vsaka naslednja ponovitev rešitve tega problema O(1).</p>

<p>Pravilo za gradnjo hiše se kot nova plast naloži na vrh plasti prejšnjih pravil in tako dalje. Vsaka plast pravil lahko uporablja vse nižje plasti in nobene od višjih plasti. Najnižjo (začetno) plast predstavlja samo mikrojedro, ki je samozadostno.</p>

<p>Ta koncept vsebinsko sovpada tudi z razvojem umetne inteligence, kjer so stroji sposobni prevzemati vedno večji del klicev teh funkcij (npr. algoritem v gradbenem podjetju takoj po prejemu plačila avtomatsko poišče dobavitelje, naroči material in organizira transport). V končni fazi pa bodo algoritmi sposobni tudi načrtovanja novih funkcij preko abstrakcij obstoječih dejstev o svetu. A do tja je še daleč. Za začetek je pomembno samo to, da pripravimo podlago, ki bo omogočila, da se bo vse skupaj začelo.</p>

<!-- Disqus start -->
<div id="disqus_thread"></div>
<script>
var disqus_config = function() {
    this.page.url = "http://docs.doktrina.org/pages/1";
    this.page.identifier = "_tmp_page_1";
};
(function() {
var d = document, s = d.createElement('script');
s.src = 'https://doktrina-1.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<!-- Disqus end -->
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
</body>
</html>
